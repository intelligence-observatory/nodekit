# This file is automatically generated by pyo3_stub_gen
# ruff: noqa: E501, F401

import builtins
import enum
import typing

@typing.final
class AudioFrame:
    r"""
    A frame of audio data.
    """
    @property
    def buffer(self) -> builtins.bytes:
        r"""
        Raw wav data.
        """
    @property
    def rate(self) -> builtins.int:
        r"""
        The sample rate, e.g. 44100
        """
    @property
    def channels(self) -> builtins.int:
        r"""
        The number of audio channels, e.g. 2
        """
    @property
    def format(self) -> typing.Optional[AudioFormat]:
        r"""
        Use numpy to read `buffer` as this format.
        """

@typing.final
class Frame:
    r"""
    A frame of audio/visual data.
    """
    @property
    def visual(self) -> VisualFrame:
        r"""
        A raw bitmap buffer plus its width and height.
        """
    @property
    def audio(self) -> typing.Optional[AudioFrame]:
        r"""
        The audio buffer. None if there was no audio on this frame.
        """

@typing.final
class VisualFrame:
    r"""
    A raw bitmap `buffer` and its dimensions.
    """
    @property
    def buffer(self) -> builtins.bytes:
        r"""
        A raw RGB24 bitmap.
        """
    @property
    def width(self) -> builtins.int:
        r"""
        The width of the image.
        """
    @property
    def height(self) -> builtins.int:
        r"""
        The height of the image.
        """
    def save(self, path: builtins.str) -> None:
        r"""
        Write the visual frame to disk at `path` as a .png file.
        """

@typing.final
class AudioFormat(enum.Enum):
    r"""
    `AudioFrame` returns a raw byte array of wav data (`buffer`).
    Use this enum, plus numpy, to read `buffer` as the correct dtype.
    """
    U8 = ...
    I16 = ...
    I32 = ...
    I64 = ...
    F32 = ...
    F64 = ...

def render(node: typing.Any, cursor_x: builtins.float, cursor_y: builtins.float, time: builtins.int) -> Frame:
    r"""
    Given a `node`, a cursor position, and a `time` in milliseconds,
    render the audio/visual state of the node.
    """

